## Cyber Incident Response

Security event and security incident are not the same thing. NIST offers standard definitions for these.

- A security event is any observable occurrence in a system or network that related to a security function. Example of these: user accessing a file store on a server, admin changing permissions, and an attacker conducting a port scan.

- An adverse event is any event that has negative consequences. Example: malware infectiono on system, server crash, user accessing a file that they are unauthorzied to see. 

- A security incident is a violation or imminent threat of violation of computer security policies, acceptable use policies, or standard security practises. Examples: accedental loss of sensitive info, an intrusion into a computer system by an attacker, the use of a keylogger on an execs system, and launch of DoS attack.

**Every security incident includes one or more security events, but not every security event is a security incident**

- Computer security incident response teams (CSIRTs) are responsible for responding to computer security incidents that occur within an organization by following standardized response proc and incorporating their subject matter expertise and prof judgment.

- In addition, CSIRT may include representation from a diverse **stakeholders** such as IT support staff, legal counsel, HR, public relations, and marketing teams.

- Note on response teams determining severity and impact: The **functional impact** of an incident is the degree of damage that is causes to an org. 
  The **economic impact** is the amount of financial loss to the org. Also measure the down time of the service and the recoverability effort. Finally the nature of the data involved will contribute the the sev as the **information impact**

<details>
  <summary> Phases of Incident Response</summary>
    <br>
    Members of CSIRTs must respond calmly and consistently in the event of a security incident. 
  There needs to be a well thoughtout and refinded process that describes how to handle the security incident. 
  
  Simple incident response process by NIST:
  
[![incidentresponse.png](https://i.postimg.cc/zGn3pcWp/incidentresponse.png)](https://postimg.cc/TK3R3QtW)

There are loops that allow responders to return to prior phases as needed. For example the containment process often includes several loops back through the detection and analysis phase to identify if the incident has been successfuly resolved. 

##Preparation

Gather the hardware, software, and info req to conduct an incident investigation. NIST Recommendations:

- Digital forensic workstations 
- Backup devices
- Laptops for data collection, analysis, and reporting
- Spare server and networking equipment
- Blank removable drive
- portable printer
- Forensic and packet cap software
- Bootable USB media containing trusted copies of forensic tools
- Office supplies and evidence collection materials

Planning is not one and done, whenever the Org is not actively invloved in an incident response effort, it should be planning for the next incident. 

## Detection and Analysis

One of the trickiest to commit to a routine process. Even with tools, many incidents are only detected bc of the trained eye of an experienced analyst. 

NIST 800-61(Computer Security Incident Handling Guide) describes 4 major categories of security event indicatiors:

- Alerts: IDS, SIEM, AV, file integrity, or other monitoring 

- Logs: from any system or app

- Publicly available info: about new vulns in the wild or in a controlled env 

- People: inside or outside org that report suspicious activity that may indicate a security incident is in progress.


When any of these sources suggest a security incident, you should shift into the initial validation mode to determine of the incident is taking place and needs further action of the incident reponse process. 

NIST recommendtations for improving incident analysis effectiveness:

- Profile networks and systems to measure the characteristics of expected activity. 
- Understand normal behaviour of users, systems, networks, and apps
- Create a logging policy that specifies the info that must be logged by systems, apps, and network devices and where it is store and retention. 
- Perform event correlation to combine info from multiple sources (SIEM)
- Sync clocks across servers, workstations, and network devices for correlation of logs. (NTP) 
- Maintain an org wide knowledge base that contains critical info about systems and apps.
- capture network traffic as soon as an incident is suspected
- Filter info to reduce clutter. May have predefined filters during the prep phase to assist with further analysis.
- Seek assistance from external resources. This can be from googling an error code to coordinating with other response teams


## Containment, Eradication, and Recovery

  First passive activities to uncover and analyze info about the incident. Then active measures contain the effects of the incident, eradicate it from the network, and recover normal operations. 
  High level overview:
  
  - 1: Select containment strategy appropriate to the incident circumstances.
  - 2: Implement containment strategy to limit damage caused by incident.
  - 3: Gather additional evidence, to support response effort and potental legal action.
  - 4: Identify attacker(s) and attacking system(s)
  - 5: Eradicate the effects of the incident and recover normal business operations. 
  
  Begin asap after analysis. 
  
  **Contianment** will isolate the incident and prevent futher spreading. Primary obj is to limit dmg to org and resources. Even still you may want to gather evidence during this. 
  
   Segmentation: Putting the infected device on antoher subnet
  
   Isolation: taking off the newtork entirely and directly connected to the internet someother way to observe behaviour.
  
   - Attacker isolation: putting the attacker in a sandboxed env.
   
   Removal: Disconnect from any network. 
  
  **Eradicaiton** Remove any artifact of the incident from the network.
  
  **Recovery** Restore normal operations and correcting security controls, firewall, malware sigs, etc. Not just rebuild network but also to reduce the likelyhood of successfuly future attack.
  
  NIST defines 3 activites for secure disposition of media containing senitive data.
   
   - Clear(logical): Rewriting data on disk or reseting to factory state if rewrite is not an option.
   
   - Purge(Physical or logical): renders data recovery infeasable with state of art lab techniques. Examples: overwiritng, block erase, and cryptographic erase used through dedicated, standard device commands. Degaussing also that uses magnetic fields to disrupt data.
   
   - Destory: renders data recovery infeasable with state of art lab techniques and results in the device being unusable. Examples: disintigration, melting, pulverization, and incinerating.
  
## Post Incident Activity 

 This is for lessons learned and review internal and external evidence meet retention requirements. Document any emergany changes that occurred during the incident response as regular cahnge review would have been skipped for the urgent response to the issue.
 
 ### Lessons learned 
 
 Is at the conclusion of every incident response. Review of the incident and response to find ways to improve proc and tools for next incident. Should be facilitated by someone who was not involved in the incident response and is seen by everyone involved as an objective outsider. This allows them to facilitate this while no one else feels they have a hidden agenda.
NIST recommends the following should be answered in the lessons learned: 

- What happned at what times?
- How well did staff and management perform in responding to the incident?
- Were procs followed? were they adequate?
- What info was needed sooner?
- Were any steps taken that might have inhibited the recovery?
- What would the staff and mgmt do differently the next time a similar incident occurs? 
- How could info sharing with other orgs have been improved?
- What corrective actions can prevent similar incidents in the future?
- What indicators should be watched for in the future to detect similar incidents?
- What additional tools or resources are needed to detect, analyze, and mitigate future incidents?

After answers need to be followed up and actioned. 

### Evidence Retention

Identify external and internal evidence. If the incident may result in civil litigation or criminal prosecution, the team should consult attorneys prior to disgarding any evidence. If not then follow any retention policies put in place by the Org. If there is none, then make one. Common for two years if there is none. 

At the conclusion of the post-incident phase, the CSIRT disbands and the incident-handling cycle returns to the prep, detect, and analyze phases.

**Note: U.S Federal Gov agencies must retain all incident handling records for at least 3 years. National Archives General Records Schedule 24, item 7.**
  </details>

Missing Note between page 150 - 160

Note:

  Policy: High level and provide authority for incident response.
  
  Proc: Detailed, tactical info that CSIRT members need when responding to an incident.
  
  Playbook: Describe the specific procs to follow in the event of a specific security incident. (step by step)


- An Incident response policy should be signed by the highest authority in the company becasue it gives them the authority to do their jobs. In most cases the CEO.

- An **Attrition attack** uses brute force methods to compromise, degrade, or destroy systems, networks, or services. Like a DDoS attack intended to impair or deny access to a service or app or a brute force attack against an auth mechanism.

- Questions related to stolen devices with encryption and ask for type of information breach is none if encryption is envolved.

## Network Events

Getting visability on how the available bandwidth is being used is usally done in 3 ways:

- **Router-based monitoring:**Relies on capturing data about the traffic passing through Routers or L3 Switches (often refered to as **network flows**. Good since these devices are ususally on border of network. Technologies that capture this data are some of the following:
   
   - Netflow, sFlow, J-Flow, etc are standards for mon traffic flows. they count info about traffic at the network devices int and send the data to flow collectors. Flows may be sampled bc of the quantiity of info. 
   
   - RMON was dev to mon LAN. Operates at L 1-4. Typically in a client/server model and uses mon devices(probes) to gather data. Implemented as a MIB that provides mon groups to get info about networks and focuses flow based info like alarms, stats, history, and events. 
   
   - SNMP is often used to collect info from network devices and provide more info about the devices themselves rather than net traffic data info provided by the other capture methods.
   
 
- **Active monitoring:** Reach out to remote systems and devices to gather data. unlike flows or snmp that sends data to a collector, the active monitors are typically the data gathering location(then may forward info to a collector). Typically collects data about availability, routes, packet delay or loss, and bandwidth. Two examples:

  - Pings - ICMP. Basic up/down info.
  
  - iPerf - Tool that measures max bandwidth an IP network can handle. Public iPerf servers can do remote testing of link bandwidth in addition to internal bandwidth testing. This can help set a performance baseline. 
 
 **Note:** Router and Active mon add traffic to the network and therefore are competing with the traffic they are monitoring. So with bandwidth issues you may lose or have the data delayed as higher priority data is likley to be prioratized over monitoring data.
 
- **Passive monitoring:** uses a tap, caps traffic as it passes. Does not add additional traffic to the network. Preforms after hte fact analysis since packets must be cap and analyzed rather than being recorded in real time as they are sent. This is a trade off for using passive. 


**note** if your network traffic is to much for your tools consider trend and anomaly analysis rather than looking for specific behaviours. Consider sampling rather and a complete capture.

<details>
  <summary>Network Monitoring Tools</summary>
    <br>
  You need to gather info from multiple network sources and combine that data into useful views for analysis and reporting.
  
  - **PRTG(Paessler Router Traffic Grapher):** Common for monitoring network bandwidth. Also has server, network, and bandwidth mon. Combines 4 diff types of mon to accuratly picture bandwidth utilz:
  
    - Packet sniffing: Mon headers to see type of traffic. Encrypted may not show much.
    
    - Flows: can send data about all connections or a sampled data set.
    
    - SNMP: Received from devices by traps.
    
    - WMI(Windows Management Intrumentation): Int for scripts and app access for automation of admin tasks as well as means of accessing mgmt data for the OS and provide reports to tools like System Center Operations Manager for Windows systems. A hybrid mode allows access to Windows performance cntrs using the remote registry service, with WMI as a fallback. This makes a windows system's native mon capability useful for central view. 
    
 
 - **Solar Winds:** Sells a variaty of network mon tools aimed at net troubleshooting and bandwidth mgmt:
 
    - NetFlowAnalyzer: Net bandwidth analyzer using flows to show a dashboard of endpoints, utilz, and flow source. Can drill down on any linked data.
    
    - Net Performance Monitor: Build around network fault detection and availability mgmt. Dashboards usually show data of one device and able to drill down into device log. overall network health can be veiwed from the tool.
    
 Combining both can give a great view of waht is occuring in a network. Pairing tools is always a good idea.
 
 -**Nagios:** Popular net and system log tool. Lots of plugins as well as your own from perl or exe apps. Broad range of mon abilities. Nagios core has GUI view of systems, services and mon capabilites. From here you can quickly review issues based on sev. Has differnt views for differemt mons like host output. Items can be categorized based on log levels and alerting thresholds. 
   Has two versions, core(free & open source) and XL(commercial) 
   
 -**Cacti:** Open source, uses SNMP polling to poll net devices for status info and provides a graphical view of data. Scripts can add more data by using data stored in a DB. Leverages RRDTool, a graphing and analysis package to provide graphical views of the data gathered.
 </details>

## Detecting Common Network Issues

 Now that you have visability of your network, you can track common network issues such as:
 
  - **Bandwidth consumption:** can cause outages and disruptions. Mon data that is sent to a central location and sends bandwidth usage alarms, other technqiues to help detect are: tools like PRTG that use flow data, trends, status indicating utilization, mon tools that can check utilz, Real time or near time graphs can be used to mon, and SNMP data can be used to mon for high load and other signs of high utilz.
  
 - **Link Failure:** Physical failures, at network layer due to bad hardware, firmware, or software. Replacing cables and interface modules are a good first TS step. SNMP or syslogs are good direct ways to detect link failure. Net flow mon can help as well. 
 
 - **Beaconing:** Heartbeats sent to C&C is typically HTTP or HTTPS traffic. Can req commands, provide status, download additional malware, etc. Usually blends into regular traffic and is encrypted and can be hard to detect. Detecting is ususally by IDS/IPS rules that ID known botnet controllers or botnet specific behaviour. Also use flow / traffic mon to ensure that systems are not sending unexpected traffic that could be beaconing(inspect outbound traffic). 
 
 - **Unexpected Traffic:** i.e scans/probes, peer-to-peer traffic, or direct attack traffic. Unexpected traffic can be detected using behaviour based detection built into IDS/IPS , trafic mon, or manual observation. Expected vs unexpected relies on 3 major techniques:
 
   - Baselines or anomaly based detection: Alarms for any passing of thresholds or deviation of baseline.
   
   - Heuristic or behaviour based detection: Network security devices and defined rules for attack traffic and other network issues.
   
   - Protocol analysis: To mon for unexpected protocols being used. 
 
 All of these are common problems, but the cause of each type can be quite varied.

DoS = One system, usually leveaging a vuln in a system or service to disrupt. 

DDoS = many systems overwhelming a service or system. Low Orbit Ion Cannon(LOIC) make participation in DDoS attacks voluntary hactivist effort from groups like annon. Knowing why your org is a target is a good start to plan and respond to DDoS.
 
 During incident reponse CLI tools to analyze network (netstat) can help with TS on local servers, but a view from the network or service perspective will typically provide a broader view of the issue. 
 
 - **Two Common Ways to Survive a DDoS attack:** 
     
     -1 a dedicate service to handle attacks. Large distributed network & DDoS mitigation tools. DDoS mit system distributes copies of a website's content to globally dist content distb net (CDN) servers while blocking DDoS attacks using a centrally managed defense mechanism. Ensures legit users get content from CDN near them while avoiding potential issues with the main website or networks it that serve it during a DDoS.
     
     -2 Deploy a DDoS mitigation device or tech. Analyze flows or sit inline between public and protected systems. Gather data to provide a view of traffic/ net and rediret or drop bad trafic based on signatures and behavious analysis.
     
 
## Wireless Rouge Devices VS Wired Rouge Devices

 - **Wired:** Rely on open or unauth networks to connect (no port security) or NAC. A wired rouge usually means: 
   
   1. an employee or other trusted member has connected a device Wout permissions or proper process. This may be just a mistake.
   
   2. An attacker has connected a device to the network.
   
 These should be responded to quickly and appropriatly. 
 
- **Wireless:** Not pyhsical location to track, will need signal strength tools to track, port scan W/ OS detection can help. 
  There is also the case of rouge AP (AP attached to network that does not properly auth wireless users) and Evil Twin that pretends to be network and get legit users to connect to. 
  
  
 
## Investigating Host Issues

System mon tools to ID unexpected behaviour. Good for security and day-to-day health. 

 - System Resource utiliz info can reveal a problem
 
 - Processor Mon: CPU consumption time, utilz, and running processes can be useful info. Spikes can indicate new process or software, constatntly high usage can reveal a DoS condition. CPU load wont tell whole story but needs to be apart of investigation / mon.
 
 - Memory mon: OS level mem mon focuses on meme utilz. Focus on consumption and process ID. Protective measures agains mem based attacks include OS built in mem mgmt or when code is compiled. Most mon look for usage of mem and set usage thresolds for alerting. 
 
   **note** Win may have a code stating buffer overflow but may not be the case, all this is stating is that an app req data but did not have sufficient mem space allocated. The windows buffer overflow tag just indicates insufficiant mem allocation.
   
 - Memory Leaks: freq cause of crashes and outages. When program doesnt release memory after it is no longer needed. It will consume more until the app fails or OS runs out of available mem. Mon mem. If no patch then periodic restart of service to mitigate. 
 
 - Drive Capacity Mon: Specific drive cap levels to prevent drive from filling up. Tools to mon like central mon and managemenet systems like System Center Operating Manager(SCOM) for Windows, Nagios for linux. System Center Config Manager (SCCM) can provide info about the disk but not in real time. Real time mon will help outages and other issues.
 
 - System Resource Mon Tools: Windows build in *Resource Monitor* or *resmon*. IT can show usage and what process is using how much and what resource. Such as what process is making what TCP connections. *Performance Monitor* or *perfmon* for windows provides more details such as energy usage , disk and network usage. It supports collection from remote systems. Perfmon is better for data collection where resmon is more for a basic usage check. Perfmon can be config with mon for resources and can be combined into user defined report(s). The sysinternals suite for Windows provides extensive mon cap beyond the builtin tools.
 
  Linux: 
  
   - ps: info for CPU, mem, process start time, and process uptime, and the command that started the process. 
      
   - top: CPU utilz, mem utilz, details about running procs, and provides interaction via hotkeys such as allowing quick ID of top consumers by entering **A**
   
   - df: report of systems disk usage, provides more info and formatting with flags
   
   - w: shows logged in accounts.
   
   Other available tools, but these are main ones. 
   
 ## Unauth Access, Changes, and Priv
 
  Ways to mon this and what would be involved:
  
  Unauth Access: 
   
   -Data logged:Authentication/User Creation
    
   -Location of Data: Auth logs/user creation logs
   
   - Analysis Tools: Central Mgmt suite/ SIM/SIEM
  
  
  Unauth Change: 
  
   -Data logged: File Creation/ Setting Change
    
   -Location of Data: System logs/App logs/Mon Tools
   
   - Analysis Tools: Central Mgmt suite/ SIM or SIEM/ Integrity Checks
  
  
  Unauth Priv use
   
   -Data logged: Priv use attempts/Priv escalation
    
   -Location of Data: Security Event logs/ App logs
   
   - Analysis Tools: SIM or SIEM/ Log analysis tools
  
 
Tools like Sysinternals' AccessChk can help validate the access that a specific user or group has to objects for Windows. For linux a script may be needed to check specific priv you are concerned about. 

##Investigate Service and App Issues

Typical App and service mon areas: Up/down, Performance, Transactional logging(info about the funtion of the service is cap, such as what actions users take or preformed), and app or service logging(logs about the function or status of the service).

Tools to help in investigation service/app anomalious behavious: Animalware and antivirus, File integrity, whitelisting tools.

Windows provides WinDbg for debugging issues, crash dump.

Windows service stats: via services.msc (Services Admin Tool) or CLI tool sc (Service Controller App). Powershell also has Start-Service to interact with services on local or remote windows hosts.

Linux Service stats: service [service name] status, service --status-all, or init.d (/etc/init.d/servicename status (this varies of dist)

App error mon: Win app logs or sometimes deticated app logs in own location. Can certalize this with SCOM. For linux usually in /var/log. 

App behavious analysis: requires combo of DOC of apps normal behaviour , logging, Heristic(behavioral) analysis using antimalware tools and other security mon tools.

App and service issue response and resotration: Can have automated scripts to run when an error code is handled. These need to be carefully tested.

 
<details>
  <summary>Forensics</summary>
    <br>
  - First step is to gather the right tools. What type of investigation, what types of systems you will analyze, and what evidentiary standards you will need to comply with before you build your toolkit.
  
  - Mobile device forensics creates more issues, diversity of OS, connecton types, security options, and software versions. 
  
  - **Toolkit** needs capabilities such as imaging, analysis, hasing and validation, process and memory dump analysis, password cracking, and log viewers. 
  
  **Imaging Notes** - A common first step in an investigation is to image drives with an imaging utility to create forensic image of the disk, a disk partition, or logical volume. **Forensic image is bit stream, includes slack and unallocated space** 
  
  - Forensic copy and wiping programs may not correctly handle spare sectors and bad sectors on HDDs or reserved space retained to help with wear leveling for SSDs. This may cause you to miss useful forensic data. Be aware of this.
  
  **Analysis Utilities**- Tries to give insight as to what happened on a device with: 
  
   -Timeline of system changes
   
   - validation tools to check known-good versions of files against ones found on the system
   
   - File System Analysis capabilites that can look at FS metadata to ID file changes, access, and deletions ( one for Windows is Windows Master File Table for NTFS)
   
   - Windows Registry Analysis
   
   - Log File parsing and review
 
   - Opensource: SIFT, CAINE, Autopsy
   
   - Commercial: FTK, encase
   
   - Commercial may be easier to defend in court, so professionals may choose to use commercial tools.
   
  
 - Live memory cap can hold encryption keys for full disk encryption products like bitlocker. So can hibernation files and crash dumps. 
 
 **Password Cracking**: Elcoms' Advanced Office Password Breaker (AOPB) can brute force password breaking for a range of file types. 
 
 **Cryptography Tools**: Many malware packages use "packers", intended to protect them from reverse engineering. Intend to made direct analysis of the code difficult or impossible. Some forensic tools support for unpacking and decoding from packing techniques like B64 encoding.
 
 
 **Forensic Process**
 1. Determine what you are trying to find out. Determine forensic activites.
 2. Outline locations of data. You may not know specific hardware or log locations, but you should be able to come up with types of data and systems.
 3. Document and review plan.
 4. Acquire and preserve evidence.
 5. Analysis. Track actions, systems and data touched, and findings. 
 6. Pivot off analysis to dig deeper. Review data from the initial analysis. looking at data that the inital analysis pointed to.
 7. Report on the findings.
 
 Aquisition follows the order of volatility:
 CPU cache, Registers, run proc, RAM -> network traffic -> Disk Drives -> Backups, printouts, optical media
 
 **Imaging tools**
 
 dd - Linux tool
  - clone drives in RAW format
  - bit-by-bit
  - if = input
  - of = output
  
 FTK - Windows tools
    
   - meta tags for chain of custody
   - GUI based

**Live imaging**
 - Can leave remnants of data due to tools being mounted from drive or installed
 - usually does not include unallocated space

**USB history**
Windows tracks USB history. USB Historian can be used to get his info from a mounted drive image. 

**Memory Capture**

 Tools: 
  fmem/LiME - Linux modules that allow access to physical mem. 
  
   fmem: is designed to be used with dd or similar
  
   lime directly copies data to a path or file

  DumpIt: Win mem, that copies a systems physical memory to the foler where DumpIt is. Allows easy cap to a usb this way.

  Volatility Framework: supports Win, mac, linux. Capabilities such as encrypt key and passphrase extract, user activity  analysis, and rootkit analysis

  EnCase and FTK have built-in memory cap and analysis capabilities


core dumps and crash dumps can provide useful forensic info. They contain contents of live memory. Can provide access to data not on disk, such as memory resident keys and malware that runs only in mem.

Windows crash dump file: CTL panel -> sys & sec -> sys -> Adv sys settings -> Startup & rec -> settings

Crash dump: Typically in system root, %systemRool%\MEMORY.DMP.

Both can be analyzed with WinDbg


**Mobile Device**
 
 - Disable passcode to ensure access
 - Devices can be resisitant to imaging if the passcode is unknown

four primary modes of data aq
  
  1. **Physical** - SIM car, mem card, or backup
  
  2. **Logical** Usually req a forensic tool to create an image of the logical storage volumes.
  
  3. **Manual Access** reviewing contents of live, unlocked devicetaking pics and notes of found items
  
  4. **File System** which can provide details of deleted and exisiting files and dir.
  
  
**Example Forensic Investigation**

1. Import image

2. Analyze Image

3. Reporting
  
  *Should include these 3 components*
  
  - Goals and Scope of investigation (scope, person/org who asked for the investigation)
  
  - Target(s) of investigation: devices, systems, and media. This should be highly detailed with info such as inv #, device model, drive type model and serial #. If there are a lot of devices, then this list will be moved to an appendix. 
  
  - List of all findings: List what was discovered, how it was, and why it is important. 

 </details>

NIST Guides:

SP-800-61 Computer Security Incident Handling Guide

SP-800-53 Security and Privacy Controls for Federal Information Systems and Organizations

SP-800-88 Guidelines for Media Sanitization

SP-800-18 Guide for Developing Security Plans for Federal Info Systems.

Template:

<details>
  <summary></summary>
    <br>
 </details>
